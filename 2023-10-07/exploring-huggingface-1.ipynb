{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973c8a0e-839c-4281-b0c6-1dc4d7ec2a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.12.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (1.24.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (23.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.17.3)\n",
      "Requirement already satisfied: requests in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.4.0)\n",
      "Requirement already satisfied: protobuf in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (2023.9.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tina/tf-demo/tensorflow-dev/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f553d3-237b-41a6-bf68-5f05e9ebc85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 11:42:10.029723: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-07 11:42:10.102453: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-07 11:42:10.103046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 11:42:11.362599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6e7e3-c7ee-4225-ab76-bd8ec2edabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  SENTIMENT ANALYSIS\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39916f83-277f-4440-b474-5c69ddbcba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier_sentiment = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cc3a2ff-3c65-416a-8586-37c76b1fe2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9981740713119507}, {'label': 'NEGATIVE', 'score': 0.9969513416290283}]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I enjoyed the move but prefer the older version of this movie\", \"I absolutely hate pineapple in pizzas. It's an abomination.\"]\n",
    "result = classifier_sentiment(sentences)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d65f1f5d-b224-492a-b06d-9c4d39e20784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ZERO SHOT CLASSIFICATION\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeb5ec5c-2806-4da0-8915-3aeea9428aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to roberta-large-mnli and revision 130fb28 (https://huggingface.co/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier_zero_shot = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6ad5fa7-f669-46ee-8173-20aac3855c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'You can grow as a Programmer if you learn about the functional paradigm',\n",
       " 'labels': ['profession', 'education', 'politics'],\n",
       " 'scores': [0.608900249004364, 0.3632014989852905, 0.027898216620087624]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_zero_shot(\n",
    "    \"You can grow as a Programmer if you learn about the functional paradigm\",\n",
    "    candidate_labels=[\"profession\", \"politics\", \"education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6e40752-45f2-4e20-8aba-5c1aa02d8340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '\\nOn the hunt for other low-mass isolated objects, the astronomers found something they had never seen: pairs of planet-like objects with masses between 0.6 and 13 times the mass of Jupiter that appear to defy some fundamental astronomical theories.\\n',\n",
       "  'labels': ['astronomy', 'science', 'space', 'physics', 'geology', 'biology'],\n",
       "  'scores': [0.6406500935554504,\n",
       "   0.2664506435394287,\n",
       "   0.0712045356631279,\n",
       "   0.012098407372832298,\n",
       "   0.005778519436717033,\n",
       "   0.003817813703790307]},\n",
       " {'sequence': '\\nAn interview with Dante Lauretta, principal investigator of the United States’ first asteroid sample return mission: OSIRIS-REx. The spacecraft successfully returned a sample of rocks and dust from the asteroid Bennu on Sunday, Sept. 24. In this interview conducted before the sample touchdown, Lauretta discussed the return procedure, what we can hope to learn from it, what we’ve already learned from the seven-year mission, and what is next for the OSIRIS-REx spacecraft.\\n',\n",
       "  'labels': ['science', 'space', 'astronomy', 'geology', 'physics', 'biology'],\n",
       "  'scores': [0.44870638847351074,\n",
       "   0.244267076253891,\n",
       "   0.1903676688671112,\n",
       "   0.049492720514535904,\n",
       "   0.04122793301939964,\n",
       "   0.025938158854842186]}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\n",
    "\"\"\"\n",
    "On the hunt for other low-mass isolated objects, the astronomers found something they had never seen: pairs of planet-like objects with masses between 0.6 and 13 times the mass of Jupiter that appear to defy some fundamental astronomical theories.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "An interview with Dante Lauretta, principal investigator of the United States’ first asteroid sample return mission: OSIRIS-REx. The spacecraft successfully returned a sample of rocks and dust from the asteroid Bennu on Sunday, Sept. 24. In this interview conducted before the sample touchdown, Lauretta discussed the return procedure, what we can hope to learn from it, what we’ve already learned from the seven-year mission, and what is next for the OSIRIS-REx spacecraft.\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "labels=[\"science\", \"physics\", \"space\", \"biology\", \"geology\", \"astronomy\"]\n",
    "\n",
    "classifier_zero_shot(text, candidate_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1797b801-fe43-482f-b38a-ab2ac88a5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TEXT GENERATION\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "390f6648-531d-480b-9bb3-2245adf36f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dbeecac6ca40c39a1c1d01408fd3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66cd7f984a44bd2b250859f28acc01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514dab38d3bb45ed9425c2da4d2a39a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336fed1654874256881812bce8b305af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616ae44c4e8e4cd1b71949ed7565d2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99bba9f3-09ad-4900-bd7c-3787b367c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'To keep a better work-life balance we should make it a \\'normal work relationship\\' or else they will come off as a bit too\\'manly\\'.\\n\\n\"Maybe you only do one or two to three working nights a week, even'},\n",
       " {'generated_text': 'To keep a better work-life balance we should be able to give people the tools available to them so they can live a productive and prosperous life,\" said Naveen.\\n\\nThe proposal of the project is already being approved by the Ontario government'},\n",
       " {'generated_text': 'To keep a better work-life balance we should start talking about the difference between work and leisure, and talk about my personal experience as I have tried to cut back to this.\\n\\nThe main distinction is that leisure is a way of life,'},\n",
       " {'generated_text': 'To keep a better work-life balance we should be able to get our work done together instead of getting in touch with other people. This is also likely to decrease the number of job opportunities that would be available, and reduce both our work-life'},\n",
       " {'generated_text': \"To keep a better work-life balance we should start to focus on our business goals.\\n\\nThe bottom line? Even when they're not at their absolute best you have work to do.\"}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"To keep a better work-life balance we should\",\n",
    "          max_length=50,\n",
    "          num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e86ff-e9ad-4338-a6ef-072fc329feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# MASK FILLING\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7e76ab9-dec5-4824-95e9-e7d6e5a26e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the weights of TFRobertaForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc0bd141-7a1c-4cb2-ac52-e03399f160d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.04847158491611481,\n",
       "  'token': 4758,\n",
       "  'token_str': ' cat',\n",
       "  'sequence': 'My silly cat scratched my hand.'},\n",
       " {'score': 0.04129023104906082,\n",
       "  'token': 25684,\n",
       "  'token_str': ' monkey',\n",
       "  'sequence': 'My silly monkey scratched my hand.'},\n",
       " {'score': 0.03429115563631058,\n",
       "  'token': 8411,\n",
       "  'token_str': ' finger',\n",
       "  'sequence': 'My silly finger scratched my hand.'},\n",
       " {'score': 0.03389035910367966,\n",
       "  'token': 10802,\n",
       "  'token_str': ' fingers',\n",
       "  'sequence': 'My silly fingers scratched my hand.'},\n",
       " {'score': 0.030509978532791138,\n",
       "  'token': 2335,\n",
       "  'token_str': ' dog',\n",
       "  'sequence': 'My silly dog scratched my hand.'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"My silly <mask> scratched my hand.\",top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "426038c8-8cde-460a-9eeb-3803d3402c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NAME ENTITY RECOGNITION\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1df8d6f6-ea18-4235-ae9b-f9ba93188a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9d36a4c-7c67-44d9-b53c-16c924b0c54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9764163,\n",
       "  'word': 'Sharif University of Technology',\n",
       "  'start': 11,\n",
       "  'end': 42}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "WASHINGTON, Oct 6 (Reuters) - U.S. employers in September turned their back on Federal Reserve officials who said the job market was beginning to cool, adding 336,000 positions in a return to the fevered hiring seen during the coronavirus pandemic and potentially bolstering the case for another interest rate increas\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "I went to Sharif University of Technology, how does it sound, cool?\n",
    "\"\"\"\n",
    "\n",
    "ner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dca0b82-9b68-4266-8ba4-b9a9515eebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# QUESTION ANSWERING, I LIKED IT A LOT\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83eae031-bcb1-4a5d-a1d2-900cd7edfbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8f7d6b-3d86-46cc-aaa3-ad30afc197a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.33565059304237366, 'start': 22, 'end': 28, 'answer': 'jungle'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=\"Where can i get something to eat?\",\n",
    "    context=\"I am in the middle of jungle, tired and have no phone\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3328b07-f344-4d2d-8233-90bc689edb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5444028377532959, 'start': 199, 'end': 205, 'answer': 'Oliver'},\n",
       " {'score': 0.09134740382432938,\n",
       "  'start': 19,\n",
       "  'end': 38,\n",
       "  'answer': 'in a magical forest'},\n",
       " {'score': 0.9246619343757629, 'start': 199, 'end': 205, 'answer': 'Oliver'},\n",
       " {'score': 0.9230326414108276, 'start': 62, 'end': 70, 'answer': 'squirrel'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = \"\"\"\n",
    "Once upon a time, in a magical forest, there lived a curious squirrel named Sammy. Sammy loved to explore and make new friends. One day, while hopping from tree to tree, he met a friendly owl named Oliver. Oliver shared stories of the night sky, and Sammy taught him about daytime adventures. They became the best of friends, showing everyone that even creatures from different worlds could find joy in each other's company. And so, Sammy and Oliver's friendship brought happiness to the entire forest, teaching everyone the value of friendship and acceptance.\n",
    "\"\"\"\n",
    "\n",
    "q = [\n",
    "    \"who was Sammy's friend?\", \n",
    "    \"Where did sammy first met his friend?\", \n",
    "    \"What was the name of that owl?\", \n",
    "    \"What kind of animal Sammy's friend was?\"\n",
    "]\n",
    "\n",
    "question_answerer(question=q, context=c, threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0316bc59-f8a8-41dc-9dc2-38eacf1f0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TEXT SUMMARIZATION\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8958e305-6494-44dc-8f37-d4a7c15f54f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small and revision d769bba (https://huggingface.co/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76ef11b6-4949-4634-aeee-b0093a49cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'little red riding Hood was known for the bright red cape her grandmother had made for her . she wore it everywhere, earning her the affectionate nickname from the villagers . the wolf, with eyes gleaming, approached Little Red Riding Hood . \"i want you to take this basket of goodies to her cottage in the woods,\" she replied politely. \"what big ears you have!\" she strayed from the path, and a wicked grin, followed closely behind, rescuing the \\'home\" . \\'dool\\' ed . little red red \\'little red gynnas from the wood \\'deer\\' the dubbed, \\'the d\\' and the tyranny and little red Riding ... and I want ... ... to ... be \\'no,\" \\'s .'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = \"\"\"\n",
    "Once upon a time, in a quaint village nestled by the woods, lived a sweet little girl named Little Red Riding Hood. She was known for the bright red cape her grandmother had made for her. Little Red Riding Hood loved her cape so much that she wore it everywhere, earning her the affectionate nickname from the villagers.\n",
    "\n",
    "One sunny morning, Little Red Riding Hood's mother called her into the kitchen. \"Dear,\" she said, \"Your grandmother isn't feeling well. I want you to take this basket of goodies to her cottage in the woods. Be sure to stay on the path and don't talk to strangers.\"\n",
    "\n",
    "Little Red Riding Hood eagerly agreed, taking the basket filled with freshly baked bread, butter, and some berries. She tied her red cape tightly and set off into the woods.\n",
    "\n",
    "As she walked through the forest, Little Red Riding Hood hummed a cheerful tune. Birds chirped, and the sun dappled through the trees. She was completely unaware of the cunning wolf that had been lurking in the shadows.\n",
    "\n",
    "The wolf, with eyes gleaming, approached Little Red Riding Hood. \"Hello, dear child,\" he said, trying to sound as friendly as possible. \"Where are you going on such a lovely day?\"\n",
    "\n",
    "\"I'm going to visit my grandmother,\" Little Red Riding Hood replied politely.\n",
    "\n",
    "The wolf, sensing an opportunity, hatched a plan. \"Oh, what a thoughtful granddaughter you are! But the path through the woods is long and treacherous. Why don't you take the shortcut, and I'll stay here and keep you company?\"\n",
    "\n",
    "Little Red Riding Hood hesitated for a moment but then agreed, trusting the wolf's words. She strayed from the path, and the wolf, with a wicked grin, followed closely behind.\n",
    "\n",
    "Meanwhile, the grandmother, who was feeling much better than Little Red Riding Hood's mother had thought, was at her cottage, patiently waiting for her granddaughter's arrival.\n",
    "\n",
    "When Little Red Riding Hood reached the cottage, she found her grandmother looking a bit different. \"Grandmother, what big ears you have!\" she exclaimed.\n",
    "\n",
    "\"All the better to hear you with, my dear,\" replied the wolf, who was now disguised as the grandmother.\n",
    "\n",
    "Little Red Riding Hood noticed other changes too, like the big eyes, sharp teeth, and enormous paws. Fear gripped her heart as she realized the truth. \"Oh, grandmother, what big teeth you have!\"\n",
    "\n",
    "\"All the better to eat you with!\" growled the wolf before leaping out of the bed.\n",
    "\n",
    "Just as the wolf lunged at Little Red Riding Hood, a woodcutter, drawn by their commotion, burst through the door. He quickly dispatched the wolf, rescuing Little Red Riding Hood and her grandmother.\n",
    "\n",
    "From that day on, Little Red Riding Hood learned to be cautious and never to stray from the path or talk to strangers. She and her grandmother lived happily and safely in their little cottage, and the villagers never tired of hearing the tale of the brave woodcutter who had saved them both.\n",
    "\"\"\"\n",
    "\n",
    "summarizer(story, min_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb3535-3edf-4f0a-8c52-abdda4cc6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TRANSLATION : YOU DO IT https://www.kaggle.com/code/truthr/a-gentle-introduction-to-the-huggingface-pipeline\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
