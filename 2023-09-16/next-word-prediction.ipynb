{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb60c21-58e7-49b1-950b-58d065830e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb8fdd3-61b8-45b8-9b43-d3a0536b9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 5\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"5\"\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"5\"\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"5\"\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_threads)\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ca3aba5-8b8b-4f0e-8f81-e1be3211f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/tina/Downloads/ai.yml', 'r') as file:\n",
    "#     data = yaml.safe_load(file)   \n",
    "# all_texts = []\n",
    "# for inner_list in data['conversations']:\n",
    "#     for text in inner_list:\n",
    "#         all_texts.append(text)\n",
    "# print(all_texts)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8437627-1415-47a7-853f-28aa2cddaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = '/home/tina/Downloads/plato.txt'\n",
    "text = open(FILE_NAME, \"r\").read()\n",
    "all_texts = [l for l in text.split('\\n') if l != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49346907-0927-451f-bb89-335584d60a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = []\n",
    "\n",
    "pattern = r'[^a-zA-Z\\s]'\n",
    "for text in all_texts:\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    cleaned_texts.append(cleaned_text)\n",
    "# print(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8aeeacd-dc17-4d98-bcf2-d727748c9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    tokens = doc.split()\n",
    "    tokens = [' ' if w in string.punctuation else w for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1dfd9ec7-2091-4ee3-8748-858f16735a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_COUNT = 5000\n",
    "all_tokens = []\n",
    "i = 0\n",
    "\n",
    "for text in all_texts:\n",
    "    if i < LINE_COUNT:\n",
    "        tokens = clean_doc(text)\n",
    "        all_tokens.extend(tokens)\n",
    "        i += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# print(all_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9cf7d476-388f-42f9-acf1-890d1370afb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 52556\n",
      "Unique Tokens: 5135\n",
      "These are the first 50 tokens: ['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'by', 'plato', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'you', 'may', 'copy', 'give', 'it', 'away', 'or', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'the', 'republic']\n"
     ]
    }
   ],
   "source": [
    "number_of_unique_tokens = len(set(all_tokens))\n",
    "\n",
    "print('Total Tokens: %d' % len(all_tokens))\n",
    "print('Unique Tokens: %d' % number_of_unique_tokens)\n",
    "print('These are the first 50 tokens: %s' % all_tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49ed8866-3624-4490-8282-71e6242f2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 52551\n",
      "This is the first sequence: the project gutenberg ebook of\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 4\n",
    "LENGTH = SEQUENCE_LENGTH + 1\n",
    "\n",
    "sequences = list()\n",
    "for i in range(LENGTH, len(all_tokens)):\n",
    "    seq = all_tokens[i-LENGTH:i]\n",
    "    line = ' '.join(seq)\n",
    "    sequences.append(line)\n",
    "\n",
    "print ('Total Sequences: %d' % len(sequences))\n",
    "print ('This is the first sequence: {0}'.format(sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "abedbab4-bbf2-4be8-955b-32cd8da5f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d0b7f43e-9614-4cb3-933e-2ed169bda8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "sequences = tokenizer.texts_to_sequences(sequences)\n",
    "vocab_size = number_of_unique_tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3faf0646-69cf-4c5a-9eff-007ebc45aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences0 = np.array(sequences)\n",
    "X, y = sequences0[:,:-1], sequences0[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5e30f888-9a55-4bc0-8e5c-1cacfe1f7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 4, 4)              20544     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 128)               68096     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5136)              662544    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 767696 (2.93 MB)\n",
      "Trainable params: 767696 (2.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dimensions_to_represent_word = 100\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, SEQUENCE_LENGTH, input_length=SEQUENCE_LENGTH))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "# model.add(LSTM(100))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd81032e-fb59-496b-90ea-a428254fae68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 17:20:37.413325: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1079607744 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "103/103 [==============================] - 6s 44ms/step - loss: 6.8281 - accuracy: 0.0941\n",
      "Epoch 2/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.9307 - accuracy: 0.0951\n",
      "Epoch 3/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.9131 - accuracy: 0.0951\n",
      "Epoch 4/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.9025 - accuracy: 0.0951\n",
      "Epoch 5/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.8934 - accuracy: 0.0951\n",
      "Epoch 6/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.8846 - accuracy: 0.0951\n",
      "Epoch 7/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.8734 - accuracy: 0.0951\n",
      "Epoch 8/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.8578 - accuracy: 0.0951\n",
      "Epoch 9/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.8310 - accuracy: 0.0951\n",
      "Epoch 10/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.7985 - accuracy: 0.0951\n",
      "Epoch 11/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.7684 - accuracy: 0.0952\n",
      "Epoch 12/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.7404 - accuracy: 0.1022\n",
      "Epoch 13/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.6857 - accuracy: 0.1306\n",
      "Epoch 14/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.6133 - accuracy: 0.1358\n",
      "Epoch 15/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.5640 - accuracy: 0.1386\n",
      "Epoch 16/300\n",
      "103/103 [==============================] - 4s 42ms/step - loss: 5.5252 - accuracy: 0.1406\n",
      "Epoch 17/300\n",
      "103/103 [==============================] - 4s 44ms/step - loss: 5.4921 - accuracy: 0.1429\n",
      "Epoch 18/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.4593 - accuracy: 0.1445\n",
      "Epoch 19/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.4150 - accuracy: 0.1462\n",
      "Epoch 20/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.3731 - accuracy: 0.1488\n",
      "Epoch 21/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.3389 - accuracy: 0.1515\n",
      "Epoch 22/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.3079 - accuracy: 0.1535\n",
      "Epoch 23/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.2674 - accuracy: 0.1554\n",
      "Epoch 24/300\n",
      "103/103 [==============================] - 4s 43ms/step - loss: 5.2240 - accuracy: 0.1589\n",
      "Epoch 25/300\n",
      "103/103 [==============================] - 4s 44ms/step - loss: 5.1817 - accuracy: 0.1631\n",
      "Epoch 26/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 5.1393 - accuracy: 0.1666\n",
      "Epoch 27/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 5.0980 - accuracy: 0.1704\n",
      "Epoch 28/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 5.0596 - accuracy: 0.1729\n",
      "Epoch 29/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 5.0196 - accuracy: 0.1769\n",
      "Epoch 30/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.9770 - accuracy: 0.1810\n",
      "Epoch 31/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.9378 - accuracy: 0.1839\n",
      "Epoch 32/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.8993 - accuracy: 0.1863\n",
      "Epoch 33/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.8611 - accuracy: 0.1880\n",
      "Epoch 34/300\n",
      "103/103 [==============================] - 4s 44ms/step - loss: 4.8203 - accuracy: 0.1897\n",
      "Epoch 35/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 4.7803 - accuracy: 0.1906\n",
      "Epoch 36/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 4.7402 - accuracy: 0.1921\n",
      "Epoch 37/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.6981 - accuracy: 0.1943\n",
      "Epoch 38/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 4.6586 - accuracy: 0.1957\n",
      "Epoch 39/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 4.6182 - accuracy: 0.1965\n",
      "Epoch 40/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 4.5744 - accuracy: 0.2003\n",
      "Epoch 41/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 4.5301 - accuracy: 0.2011\n",
      "Epoch 42/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 4.4822 - accuracy: 0.2042\n",
      "Epoch 43/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.4426 - accuracy: 0.2046\n",
      "Epoch 44/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.3977 - accuracy: 0.2072\n",
      "Epoch 45/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.3566 - accuracy: 0.2096\n",
      "Epoch 46/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.3152 - accuracy: 0.2108\n",
      "Epoch 47/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 4.2733 - accuracy: 0.2129\n",
      "Epoch 48/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 4.2341 - accuracy: 0.2154\n",
      "Epoch 49/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 4.1925 - accuracy: 0.2187\n",
      "Epoch 50/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 4.1546 - accuracy: 0.2212\n",
      "Epoch 51/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 4.1153 - accuracy: 0.2226\n",
      "Epoch 52/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 4.0736 - accuracy: 0.2263\n",
      "Epoch 53/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 4.0346 - accuracy: 0.2294\n",
      "Epoch 54/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.9964 - accuracy: 0.2309\n",
      "Epoch 55/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.9556 - accuracy: 0.2355\n",
      "Epoch 56/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 3.9139 - accuracy: 0.2381\n",
      "Epoch 57/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 3.8773 - accuracy: 0.2435\n",
      "Epoch 58/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 3.8421 - accuracy: 0.2460\n",
      "Epoch 59/300\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 3.8057 - accuracy: 0.2501\n",
      "Epoch 60/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.7652 - accuracy: 0.2535\n",
      "Epoch 61/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 3.7322 - accuracy: 0.2573\n",
      "Epoch 62/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.6989 - accuracy: 0.2635\n",
      "Epoch 63/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.6646 - accuracy: 0.2650\n",
      "Epoch 64/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.6329 - accuracy: 0.2695\n",
      "Epoch 65/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.6003 - accuracy: 0.2726\n",
      "Epoch 66/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.5712 - accuracy: 0.2763\n",
      "Epoch 67/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 3.5425 - accuracy: 0.2804\n",
      "Epoch 68/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 3.5117 - accuracy: 0.2839\n",
      "Epoch 69/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.4819 - accuracy: 0.2874\n",
      "Epoch 70/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.4540 - accuracy: 0.2923\n",
      "Epoch 71/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 3.4296 - accuracy: 0.2936\n",
      "Epoch 72/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 3.4019 - accuracy: 0.2973\n",
      "Epoch 73/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.3748 - accuracy: 0.3013\n",
      "Epoch 74/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 3.3507 - accuracy: 0.3050\n",
      "Epoch 75/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 3.3246 - accuracy: 0.3072\n",
      "Epoch 76/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.3053 - accuracy: 0.3103\n",
      "Epoch 77/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 3.2807 - accuracy: 0.3124\n",
      "Epoch 78/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 3.2578 - accuracy: 0.3159\n",
      "Epoch 79/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 3.2340 - accuracy: 0.3196\n",
      "Epoch 80/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.2143 - accuracy: 0.3217\n",
      "Epoch 81/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 3.1930 - accuracy: 0.3250\n",
      "Epoch 82/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 3.1735 - accuracy: 0.3283\n",
      "Epoch 83/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.1542 - accuracy: 0.3311\n",
      "Epoch 84/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.1359 - accuracy: 0.3330\n",
      "Epoch 85/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.1146 - accuracy: 0.3375\n",
      "Epoch 86/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.0957 - accuracy: 0.3396\n",
      "Epoch 87/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 3.0803 - accuracy: 0.3412\n",
      "Epoch 88/300\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 3.0632 - accuracy: 0.3454\n",
      "Epoch 89/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 3.0461 - accuracy: 0.3467\n",
      "Epoch 90/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 3.0287 - accuracy: 0.3497\n",
      "Epoch 91/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 3.0103 - accuracy: 0.3511\n",
      "Epoch 92/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.9983 - accuracy: 0.3533\n",
      "Epoch 93/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.9810 - accuracy: 0.3572\n",
      "Epoch 94/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.9659 - accuracy: 0.3598\n",
      "Epoch 95/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.9533 - accuracy: 0.3605\n",
      "Epoch 96/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.9383 - accuracy: 0.3628\n",
      "Epoch 97/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.9218 - accuracy: 0.3665\n",
      "Epoch 98/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.9080 - accuracy: 0.3698\n",
      "Epoch 99/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.8964 - accuracy: 0.3692\n",
      "Epoch 100/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.8864 - accuracy: 0.3701\n",
      "Epoch 101/300\n",
      "103/103 [==============================] - 6s 53ms/step - loss: 2.8698 - accuracy: 0.3732\n",
      "Epoch 102/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.8610 - accuracy: 0.3741\n",
      "Epoch 103/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.8473 - accuracy: 0.3772\n",
      "Epoch 104/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.8322 - accuracy: 0.3780\n",
      "Epoch 105/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.8224 - accuracy: 0.3808\n",
      "Epoch 106/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.8129 - accuracy: 0.3825\n",
      "Epoch 107/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 2.7983 - accuracy: 0.3832\n",
      "Epoch 108/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.7845 - accuracy: 0.3870\n",
      "Epoch 109/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.7746 - accuracy: 0.3891\n",
      "Epoch 110/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.7639 - accuracy: 0.3901\n",
      "Epoch 111/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.7529 - accuracy: 0.3909\n",
      "Epoch 112/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.7414 - accuracy: 0.3942\n",
      "Epoch 113/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.7348 - accuracy: 0.3938\n",
      "Epoch 114/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.7245 - accuracy: 0.3962\n",
      "Epoch 115/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.7125 - accuracy: 0.3988\n",
      "Epoch 116/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.7036 - accuracy: 0.4009\n",
      "Epoch 117/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.6936 - accuracy: 0.4013\n",
      "Epoch 118/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.6839 - accuracy: 0.4033\n",
      "Epoch 119/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.6716 - accuracy: 0.4046\n",
      "Epoch 120/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.6592 - accuracy: 0.4065\n",
      "Epoch 121/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.6504 - accuracy: 0.4091\n",
      "Epoch 122/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.6448 - accuracy: 0.4100\n",
      "Epoch 123/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.6364 - accuracy: 0.4113\n",
      "Epoch 124/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.6272 - accuracy: 0.4109\n",
      "Epoch 125/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.6128 - accuracy: 0.4150\n",
      "Epoch 126/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.6074 - accuracy: 0.4155\n",
      "Epoch 127/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.6001 - accuracy: 0.4171\n",
      "Epoch 128/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 2.5915 - accuracy: 0.4190\n",
      "Epoch 129/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 2.5818 - accuracy: 0.4190\n",
      "Epoch 130/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.5722 - accuracy: 0.4208\n",
      "Epoch 131/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.5629 - accuracy: 0.4240\n",
      "Epoch 132/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.5580 - accuracy: 0.4241\n",
      "Epoch 133/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.5490 - accuracy: 0.4247\n",
      "Epoch 134/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.5405 - accuracy: 0.4242\n",
      "Epoch 135/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.5352 - accuracy: 0.4277\n",
      "Epoch 136/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.5256 - accuracy: 0.4284\n",
      "Epoch 137/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.5174 - accuracy: 0.4293\n",
      "Epoch 138/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.5106 - accuracy: 0.4312\n",
      "Epoch 139/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 2.5018 - accuracy: 0.4335\n",
      "Epoch 140/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.4950 - accuracy: 0.4336\n",
      "Epoch 141/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.4907 - accuracy: 0.4354\n",
      "Epoch 142/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.4801 - accuracy: 0.4368\n",
      "Epoch 143/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.4734 - accuracy: 0.4375\n",
      "Epoch 144/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.4657 - accuracy: 0.4398\n",
      "Epoch 145/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.4559 - accuracy: 0.4402\n",
      "Epoch 146/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.4480 - accuracy: 0.4418\n",
      "Epoch 147/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.4409 - accuracy: 0.4434\n",
      "Epoch 148/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.4366 - accuracy: 0.4441\n",
      "Epoch 149/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.4294 - accuracy: 0.4461\n",
      "Epoch 150/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.4206 - accuracy: 0.4470\n",
      "Epoch 151/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.4186 - accuracy: 0.4468\n",
      "Epoch 152/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 2.4081 - accuracy: 0.4499\n",
      "Epoch 153/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.4013 - accuracy: 0.4500\n",
      "Epoch 154/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.3971 - accuracy: 0.4508\n",
      "Epoch 155/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.3882 - accuracy: 0.4519\n",
      "Epoch 156/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 2.3819 - accuracy: 0.4545\n",
      "Epoch 157/300\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 2.3787 - accuracy: 0.4523\n",
      "Epoch 158/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.3668 - accuracy: 0.4561\n",
      "Epoch 159/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.3606 - accuracy: 0.4580\n",
      "Epoch 160/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.3531 - accuracy: 0.4588\n",
      "Epoch 161/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 2.3476 - accuracy: 0.4577\n",
      "Epoch 162/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.3426 - accuracy: 0.4600\n",
      "Epoch 163/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.3344 - accuracy: 0.4630\n",
      "Epoch 164/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.3301 - accuracy: 0.4628\n",
      "Epoch 165/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.3243 - accuracy: 0.4649\n",
      "Epoch 166/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.3161 - accuracy: 0.4653\n",
      "Epoch 167/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 2.3112 - accuracy: 0.4658\n",
      "Epoch 168/300\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 2.3030 - accuracy: 0.4690\n",
      "Epoch 169/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.2986 - accuracy: 0.4682\n",
      "Epoch 170/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2919 - accuracy: 0.4686\n",
      "Epoch 171/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2852 - accuracy: 0.4699\n",
      "Epoch 172/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2811 - accuracy: 0.4715\n",
      "Epoch 173/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.2733 - accuracy: 0.4733\n",
      "Epoch 174/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 2.2670 - accuracy: 0.4737\n",
      "Epoch 175/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2615 - accuracy: 0.4755\n",
      "Epoch 176/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.2576 - accuracy: 0.4750\n",
      "Epoch 177/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.2494 - accuracy: 0.4787\n",
      "Epoch 178/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.2424 - accuracy: 0.4771\n",
      "Epoch 179/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2398 - accuracy: 0.4794\n",
      "Epoch 180/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.2330 - accuracy: 0.4780\n",
      "Epoch 181/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2260 - accuracy: 0.4819\n",
      "Epoch 182/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.2206 - accuracy: 0.4811\n",
      "Epoch 183/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 2.2155 - accuracy: 0.4831\n",
      "Epoch 184/300\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 2.2084 - accuracy: 0.4841\n",
      "Epoch 185/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.2044 - accuracy: 0.4847\n",
      "Epoch 186/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.1987 - accuracy: 0.4871\n",
      "Epoch 187/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.1938 - accuracy: 0.4886\n",
      "Epoch 188/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.1897 - accuracy: 0.4882\n",
      "Epoch 189/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 2.1831 - accuracy: 0.4898\n",
      "Epoch 190/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.1789 - accuracy: 0.4887\n",
      "Epoch 191/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.1735 - accuracy: 0.4906\n",
      "Epoch 192/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 2.1646 - accuracy: 0.4941\n",
      "Epoch 193/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.1602 - accuracy: 0.4933\n",
      "Epoch 194/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.1521 - accuracy: 0.4946\n",
      "Epoch 195/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.1508 - accuracy: 0.4959\n",
      "Epoch 196/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.1469 - accuracy: 0.4953\n",
      "Epoch 197/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.1412 - accuracy: 0.4982\n",
      "Epoch 198/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 2.1347 - accuracy: 0.4978\n",
      "Epoch 199/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.1262 - accuracy: 0.4993\n",
      "Epoch 200/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.1258 - accuracy: 0.4994\n",
      "Epoch 201/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.1207 - accuracy: 0.4992\n",
      "Epoch 202/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.1129 - accuracy: 0.5013\n",
      "Epoch 203/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.1060 - accuracy: 0.5029\n",
      "Epoch 204/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.1077 - accuracy: 0.5031\n",
      "Epoch 205/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.0997 - accuracy: 0.5063\n",
      "Epoch 206/300\n",
      "103/103 [==============================] - 6s 55ms/step - loss: 2.0926 - accuracy: 0.5063\n",
      "Epoch 207/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.0888 - accuracy: 0.5071\n",
      "Epoch 208/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.0848 - accuracy: 0.5079\n",
      "Epoch 209/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.0804 - accuracy: 0.5076\n",
      "Epoch 210/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.0736 - accuracy: 0.5096\n",
      "Epoch 211/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 2.0666 - accuracy: 0.5123\n",
      "Epoch 212/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 2.0646 - accuracy: 0.5109\n",
      "Epoch 213/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 2.0584 - accuracy: 0.5119\n",
      "Epoch 214/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.0548 - accuracy: 0.5124\n",
      "Epoch 215/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.0520 - accuracy: 0.5122\n",
      "Epoch 216/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.0483 - accuracy: 0.5148\n",
      "Epoch 217/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 2.0372 - accuracy: 0.5165\n",
      "Epoch 218/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.0355 - accuracy: 0.5161\n",
      "Epoch 219/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 2.0320 - accuracy: 0.5184\n",
      "Epoch 220/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 2.0243 - accuracy: 0.5187\n",
      "Epoch 221/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.0222 - accuracy: 0.5193\n",
      "Epoch 222/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.0167 - accuracy: 0.5204\n",
      "Epoch 223/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.0080 - accuracy: 0.5221\n",
      "Epoch 224/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 2.0068 - accuracy: 0.5217\n",
      "Epoch 225/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 2.0054 - accuracy: 0.5217\n",
      "Epoch 226/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 1.9981 - accuracy: 0.5238\n",
      "Epoch 227/300\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 1.9969 - accuracy: 0.5230\n",
      "Epoch 228/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.9902 - accuracy: 0.5244\n",
      "Epoch 229/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 1.9847 - accuracy: 0.5269\n",
      "Epoch 230/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.9784 - accuracy: 0.5278\n",
      "Epoch 231/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.9754 - accuracy: 0.5271\n",
      "Epoch 232/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 1.9709 - accuracy: 0.5293\n",
      "Epoch 233/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.9642 - accuracy: 0.5295\n",
      "Epoch 234/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.9596 - accuracy: 0.5304\n",
      "Epoch 235/300\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 1.9576 - accuracy: 0.5328\n",
      "Epoch 236/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.9490 - accuracy: 0.5336\n",
      "Epoch 237/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.9480 - accuracy: 0.5334\n",
      "Epoch 238/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.9425 - accuracy: 0.5333\n",
      "Epoch 239/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 1.9358 - accuracy: 0.5351\n",
      "Epoch 240/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.9348 - accuracy: 0.5357\n",
      "Epoch 241/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.9287 - accuracy: 0.5367\n",
      "Epoch 242/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.9276 - accuracy: 0.5385\n",
      "Epoch 243/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.9232 - accuracy: 0.5395\n",
      "Epoch 244/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.9188 - accuracy: 0.5382\n",
      "Epoch 245/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.9153 - accuracy: 0.5408\n",
      "Epoch 246/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 1.9070 - accuracy: 0.5417\n",
      "Epoch 247/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.9029 - accuracy: 0.5419\n",
      "Epoch 248/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 1.8988 - accuracy: 0.5427\n",
      "Epoch 249/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.8940 - accuracy: 0.5445\n",
      "Epoch 250/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 1.8894 - accuracy: 0.5444\n",
      "Epoch 251/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.8852 - accuracy: 0.5449\n",
      "Epoch 252/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.8843 - accuracy: 0.5460\n",
      "Epoch 253/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.8815 - accuracy: 0.5457\n",
      "Epoch 254/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.8770 - accuracy: 0.5466\n",
      "Epoch 255/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 1.8688 - accuracy: 0.5494\n",
      "Epoch 256/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 1.8645 - accuracy: 0.5503\n",
      "Epoch 257/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.8618 - accuracy: 0.5498\n",
      "Epoch 258/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 1.8580 - accuracy: 0.5517\n",
      "Epoch 259/300\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 1.8541 - accuracy: 0.5517\n",
      "Epoch 260/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.8500 - accuracy: 0.5529\n",
      "Epoch 261/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.8478 - accuracy: 0.5525\n",
      "Epoch 262/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.8409 - accuracy: 0.5535\n",
      "Epoch 263/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.8369 - accuracy: 0.5558\n",
      "Epoch 264/300\n",
      "103/103 [==============================] - 5s 53ms/step - loss: 1.8327 - accuracy: 0.5563\n",
      "Epoch 265/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.8295 - accuracy: 0.5566\n",
      "Epoch 266/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.8269 - accuracy: 0.5569\n",
      "Epoch 267/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.8184 - accuracy: 0.5582\n",
      "Epoch 268/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 1.8179 - accuracy: 0.5599\n",
      "Epoch 269/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.8168 - accuracy: 0.5580\n",
      "Epoch 270/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.8115 - accuracy: 0.5602\n",
      "Epoch 271/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.8076 - accuracy: 0.5602\n",
      "Epoch 272/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.8023 - accuracy: 0.5607\n",
      "Epoch 273/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 1.7958 - accuracy: 0.5646\n",
      "Epoch 274/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7931 - accuracy: 0.5646\n",
      "Epoch 275/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7897 - accuracy: 0.5669\n",
      "Epoch 276/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.7839 - accuracy: 0.5651\n",
      "Epoch 277/300\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 1.7836 - accuracy: 0.5657\n",
      "Epoch 278/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 1.7793 - accuracy: 0.5658\n",
      "Epoch 279/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.7760 - accuracy: 0.5674\n",
      "Epoch 280/300\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 1.7699 - accuracy: 0.5685\n",
      "Epoch 281/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 1.7672 - accuracy: 0.5688\n",
      "Epoch 282/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7684 - accuracy: 0.5682\n",
      "Epoch 283/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 1.7600 - accuracy: 0.5699\n",
      "Epoch 284/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.7567 - accuracy: 0.5724\n",
      "Epoch 285/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.7550 - accuracy: 0.5716\n",
      "Epoch 286/300\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 1.7471 - accuracy: 0.5735\n",
      "Epoch 287/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7412 - accuracy: 0.5755\n",
      "Epoch 288/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.7384 - accuracy: 0.5765\n",
      "Epoch 289/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7353 - accuracy: 0.5769\n",
      "Epoch 290/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.7303 - accuracy: 0.5782\n",
      "Epoch 291/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 1.7270 - accuracy: 0.5786\n",
      "Epoch 292/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7257 - accuracy: 0.5799\n",
      "Epoch 293/300\n",
      "103/103 [==============================] - 5s 49ms/step - loss: 1.7245 - accuracy: 0.5765\n",
      "Epoch 294/300\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 1.7218 - accuracy: 0.5795\n",
      "Epoch 295/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 1.7192 - accuracy: 0.5785\n",
      "Epoch 296/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7113 - accuracy: 0.5796\n",
      "Epoch 297/300\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 1.7065 - accuracy: 0.5810\n",
      "Epoch 298/300\n",
      "103/103 [==============================] - 5s 48ms/step - loss: 1.7050 - accuracy: 0.5823\n",
      "Epoch 299/300\n",
      "103/103 [==============================] - 5s 46ms/step - loss: 1.7009 - accuracy: 0.5834\n",
      "Epoch 300/300\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 1.6967 - accuracy: 0.5845\n",
      "INFO:tensorflow:Assets written to: ./data/chat-model-prediction.mdl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/chat-model-prediction.mdl/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=512, epochs=300)\n",
    "model.save(\"./data/chat-model-prediction.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de4905-c5a3-424f-93e9-c985fd0e7143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fbf1fd4a-50b5-41a5-b81c-f49c131ce7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52551, 4)\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "(1, 5136)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "prediction = model.predict(X[0].reshape(1,SEQUENCE_LENGTH))\n",
    "print (prediction.shape)\n",
    "# print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59d12f89-06dd-458e-a686-8b8a9676cb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 4, 4)              20544     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 128)               68096     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5136)              662544    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 767696 (2.93 MB)\n",
      "Trainable params: 767696 (2.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(\"./data/chat-model-prediction.mdl\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e07e7b3-d233-455c-9d9d-157cb5c04a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "who suited to raise the [29, 1144, 4, 1145, 1] [[1144    4 1145    1]] 158\n",
      "who suited to raise the  =>  question\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "suited to raise the question [1144, 4, 1145, 1, 158] [[   4 1145    1  158]] 3\n",
      "suited to raise the question  =>  and\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "to raise the question and [4, 1145, 1, 158, 3] [[1145    1  158    3]] 1172\n",
      "to raise the question and  =>  preparing\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "raise the question and preparing [1145, 1, 158, 3, 1172] [[   1  158    3 1172]] 4\n",
      "raise the question and preparing  =>  to\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    'the extent to which',\n",
    "    'many affinities may be',\n",
    "    'empty vessel makes the',\n",
    "    \"republic is the vehicle\",\n",
    "    'who suited to raise the',\n",
    "    'suited to raise the question',\n",
    "    'to raise the question and',\n",
    "    'raise the question and preparing'\n",
    "]\n",
    "\n",
    "test_sequences = [clean_doc(text) for text in test_texts]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sequences)\n",
    "\n",
    "for i, test_sequence in enumerate(test_sequences):\n",
    "    if len(test_sequence) < SEQUENCE_LENGTH:\n",
    "        continue\n",
    "    input_sequence = test_sequence[-SEQUENCE_LENGTH:]\n",
    "    input_sequence = np.array(input_sequence).reshape(1, -1)  \n",
    "    predicted_probs = loaded_model.predict(input_sequence)\n",
    "    predicted_word_index = np.argmax(predicted_probs)\n",
    "    print(test_texts[i], test_sequence, input_sequence, predicted_word_index)\n",
    "    \n",
    "    predicted_word = tokenizer.index_word[predicted_word_index]\n",
    "    print(test_texts[i], ' => ', predicted_word)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22ddd1-78b8-40a1-b887-78645e01e06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd2090-2898-4a16-8809-544296ed88b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
