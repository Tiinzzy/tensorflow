{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866003c9-e058-4283-87d6-cfe196f8184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c4a338-b7ab-4963-b3eb-89c694066af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plato = open(\"/home/tina/Downloads/plato.txt\", \"r\").read()\n",
    "text = plato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90b9e2-98b6-4f8a-8bfb-d733ff0b05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    doc = doc.replace('--', ' ')\n",
    "    tokens = doc.split()\n",
    "    tokens = [' ' if w in string.punctuation else w for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    " \n",
    "tokens = clean_doc(text)\n",
    "\n",
    "number_of_unique_tokens = len(set(tokens))\n",
    "\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % number_of_unique_tokens)\n",
    "print('These are the first 200 tokens: %s' % tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490063ac-fb27-4ac8-ab34-6d3c976d5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 2\n",
    "\n",
    "length = sequence_length + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    seq = tokens[i-length:i]\n",
    "    line = ' '.join(seq)\n",
    "    sequences.append(line)\n",
    "\n",
    "print ('Total Sequences: %d' % len(sequences))\n",
    "print ('This is the first sequence: {0}'.format(sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fec3c-6e41-4d36-b13f-4d63daf04356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "sequences = tokenizer.texts_to_sequences(sequences)\n",
    "vocab_size = number_of_unique_tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb41d8f-006c-4916-95f3-5daefbb2642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences0 = np.array(sequences)\n",
    "X, y = sequences0[:,:-1], sequences0[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9819b7-a226-44ea-8492-c8af516b8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions_to_represent_word = 100\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, sequence_length, input_length=sequence_length))\n",
    "\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a94f7-32f3-44a5-b604-dbfdb1921d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957229c5-0aec-4bd5-a4ea-827866a7f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X.shape)\n",
    "prediction = model.predict(X[0].reshape(1,sequence_length))\n",
    "print (prediction.shape)\n",
    "print (prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
