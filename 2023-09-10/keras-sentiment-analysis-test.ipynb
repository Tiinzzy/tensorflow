{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ae011b-9a0d-4292-888e-bf11a002b3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 07:53:41.418273: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 07:53:41.455473: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 07:53:41.456089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 07:53:42.076825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers\n",
    "from keras.datasets import imdb\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22414690-7465-43cf-9699-e814034ece88",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 5\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"5\"\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"5\"\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"5\"\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_threads)\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63a5d0c-d61c-447a-b980-8b2fe9fa738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f180df-ee99-47d0-af34-14d892f3f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output categories are [0 1]\n",
      "The number of unique words is 9998\n"
     ]
    }
   ],
   "source": [
    "print(\"The output categories are\", np.unique(targets))\n",
    "print(\"The number of unique words is\", len(np.unique(np.hstack(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5751b9dd-cd36-4f02-bef8-2fc4ff4c1686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Review length is 234.75892\n",
      "The Standard Deviation is 173\n"
     ]
    }
   ],
   "source": [
    "length = [len(i) for i in data]\n",
    "print(\"The Average Review length is\", np.mean(length))\n",
    "print(\"The Standard Deviation is\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b924db99-2936-4b25-8449-dbff7af71354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Label:\", targets[0])\n",
    "# print(data[0])\n",
    "# print(len(data[0]), length[0])\n",
    "# print(sum(data[0]))\n",
    "# print(np.unique(data[0]))\n",
    "# print(len(np.unique(data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4087639-1ad1-4885-a377-71d083e86ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = imdb.get_word_index()\n",
    "def vec2text(vec):\n",
    "    reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
    "    decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in vec] )\n",
    "    return decoded\n",
    "\n",
    "def text2vector(text):\n",
    "    v = []\n",
    "    for t in text.split():\n",
    "        n = index.get(t, None)\n",
    "        if n is not None:\n",
    "            v.append(n + 3)\n",
    "        else:\n",
    "            v.append(1)\n",
    "    return v\n",
    "    \n",
    "# print(vec2text(data[0]))\n",
    "# print(text2vector(vec2text(data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54506235-1c9a-49a6-85ef-62293439cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "vdata = vectorize(data)\n",
    "targets = np.array(targets).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a666f25e-5c96-460f-9ea5-8ad067ab8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = vdata[:10000]\n",
    "test_y = targets[:10000]\n",
    "train_x = vdata[40000:]\n",
    "train_y = targets[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac35ced9-f9c6-4f9d-b24f-0fa1583b6f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 11:35:07.382759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-10 11:35:07.383514: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7c1b162-4f95-4b39-9c4e-9c8b43fb135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                500050    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505201 (1.93 MB)\n",
      "Trainable params: 505201 (1.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input - Layer\n",
    "\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "\n",
    "# Output- Layer\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89077eb3-9e5b-4d2c-9c91-eb3ceb5d8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f6f77e-d167-4c5f-9a11-e3d755586e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 11:35:14.709373: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "308/313 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.8405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 11:35:18.290135: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.3592 - accuracy: 0.8406 - val_loss: 0.3184 - val_accuracy: 0.8657\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1391 - accuracy: 0.9472 - val_loss: 0.3791 - val_accuracy: 0.8609\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0616 - accuracy: 0.9782 - val_loss: 0.5450 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.8221 - val_accuracy: 0.8375\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.7493 - val_accuracy: 0.8469\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_x, train_y, epochs= 5, batch_size = 32, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed9df4c-d103-42b9-b872-3ba0d7787044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 11:35:30.177269: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.69%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96131566-695c-42a1-a10c-bc5befd350af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/keras-sentiment.mdl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/keras-sentiment.mdl/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.saving.save_model(model, './data/keras-sentiment.mdl', overwrite=True, save_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4de57ee-e0f5-4e14-9d7c-7f674be9fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 11:35:33.273044: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.69%\n"
     ]
    }
   ],
   "source": [
    "my_model = tf.keras.saving.load_model('./data/keras-sentiment.mdl')\n",
    "scores = my_model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2bb34c3-1609-4f28-8bc4-29ecc8ad2ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "[[0.9998848]]\n"
     ]
    }
   ],
   "source": [
    "text = \"# this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little boy's that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\"\n",
    "sample_vector = vectorize([text2vector(text)])\n",
    "prediction = my_model.predict(sample_vector)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413db45-b6c2-43f6-a0f9-89ea83f0d709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84f06dd1-cdab-47fa-82bc-275af8392f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[1, 167, 2979, 8513, 2733, 186, 8, 28, 2, 107, 275, 3167, 295, 159, 582, 56, 19, 14, 1403, 5675, 6, 212, 44, 9382, 5, 6, 2616, 44, 1937, 5, 2, 12, 1901, 11, 6, 1960, 22, 5988, 299, 6, 9257, 3071, 248, 1636, 2422, 37, 166, 369, 19, 2, 2, 1083, 5616, 2567, 5, 9, 515, 260, 3068, 19, 2567, 5, 41, 223, 64, 8, 1974, 2, 658, 2901, 2, 9, 2, 1003, 1586, 2733, 47, 6, 680, 570, 5, 380, 5704, 8, 27, 414, 63, 9, 1082, 821, 885, 1134, 43, 3437, 616, 88, 164, 674, 126, 186, 8, 79, 301, 2, 1523, 2567, 267, 2, 2, 11, 41, 2, 47, 6, 2, 1826, 21, 152, 2522, 17, 322, 5, 2, 214, 1571, 19, 6, 2, 2, 217, 240, 43, 50, 8, 30, 6, 2, 4, 20, 1027, 8, 1108, 32, 4, 2, 11, 6, 356, 420, 7, 2, 3219, 217, 11, 4, 2, 4, 248, 1636, 2, 4, 4192, 223, 132, 4, 780, 322, 5, 452, 37, 494, 53, 6, 3219, 359, 18, 668, 9528, 4254, 1540, 21, 164, 7407, 266, 46, 7, 134, 1008, 237, 2733, 64, 320, 2, 2, 4, 1341, 17, 6, 564, 29, 9, 1238, 879, 7, 2, 21, 9, 4170, 7, 6, 1288, 17, 73, 5, 4, 1185, 6519, 43, 214, 32, 2, 56, 300, 241, 39]\n",
      "# director screenwriter allan burns seems to have # two different scripts together before coming up with this minor outing a comedy about infidelity and a melodrama about loss and # it results in a unfunny film christine plays a crass cynical tv news reporter who makes friends with # # mary tyler moore and is soon having dinner with moore and her family only to discover # husband ted # is # secret affair burns has a strange stop and start rhythm to his dialogue which is neither realistic nor effective just increasingly annoying because nothing important ever seems to get said # thin moore looking # # in her # has a # smile but doesn't convince as wife and # gets stuck with a # # role he's just there to be a # the movie attempts to cover all the # in a classic case of # woman's role in the # the tv news # the cheating family man the working wife and mother who wants more a woman's need for female friendships et al but nothing substantial comes out of these ideas since burns only half # # the issues as a writer he is surprisingly free of # but is devoid of a purpose as well and the heavy plotting just gets all # up 1 2 from\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[2.276341e-05]]\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "print(targets[40000+i])\n",
    "print(data[40000+i])\n",
    "text = vec2text(data[40000+i])\n",
    "print(text)\n",
    "\n",
    "sample_vector = vectorize([text2vector(text)])\n",
    "prediction = my_model.predict(sample_vector)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98e94fe8-91fa-40f0-9b45-7bed22866e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.00106448]]\n"
     ]
    }
   ],
   "source": [
    "text = 'that was an awful movie i ever seen. worst than anything.' \n",
    "sample_vector = vectorize([text2vector(text)])\n",
    "prediction = my_model.predict(sample_vector)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a31812e-50de-43b6-841c-1b5bf403e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0.9033039]]\n"
     ]
    }
   ],
   "source": [
    "text = 'never saw such an elegant plays in any other movies.' \n",
    "sample_vector = vectorize([text2vector(text)])\n",
    "prediction = my_model.predict(sample_vector)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c5d7-0dbb-4e5e-84af-5561719879c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
